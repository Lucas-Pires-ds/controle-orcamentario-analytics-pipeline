# üìä Projeto de Controle Or√ßament√°rio ‚Äî Pipeline ETL e Analytics
## Vis√£o Geral

Este projeto simula um **pipeline completo de dados para controle or√ßament√°rio**, cobrindo desde a ingest√£o de dados brutos at√© a prepara√ß√£o de um **modelo anal√≠tico pronto para consumo em Power BI**.

O foco principal n√£o √© apenas gerar dashboards, mas **demonstrar pensamento de engenharia anal√≠tica**, com aten√ß√£o especial √† **qualidade dos dados**, **rastreabilidade**, **modelagem dimensional** e **integridade referencial** ‚Äî problemas reais encontrados em ambientes corporativos.

O projeto foi desenvolvido com **SQL Server**, **Python** e **Power BI**, adotando boas pr√°ticas de arquitetura e ETL utilizadas no mercado.

> **Status do projeto:** em desenvolvimento cont√≠nuo, com evolu√ß√£o progressiva das camadas Silver e Gold e das an√°lises no Power BI.


## üéØ Problema de Neg√≥cio

Empresas que trabalham com or√ßamento frequentemente enfrentam desafios como:

* Dados financeiros vindos de m√∫ltiplas fontes e com baixa padroniza√ß√£o

* Falta de controle de qualidade antes da an√°lise

* Dificuldade em garantir consist√™ncia entre categorias, centros de custo e campanhas

Este projeto resolve esses problemas ao estruturar um pipeline que:

* Centraliza os dados

* Sanea inconsist√™ncias ainda na camada de dados

* Entrega dimens√µes confi√°veis para an√°lises financeiras e or√ßament√°rias

## üèóÔ∏è Arquitetura de Dados

![Arquitetura do Pipeline de Dados](docs_e_imagens/diagrama_pipeline_de_dados.png)

Foi adotado o padr√£o Medallion Architecture, separando claramente as responsabilidades de cada camada:

### ü•â Camada Bronze (stg_)

* Ingest√£o de dados brutos via **Python (Pandas) + Bulk Insert**

* Todas as colunas armazenadas como VARCHAR(MAX) ou VARCHAR(200)

* Objetivo: **garantir que a carga nunca falhe por incompatibilidade de tipos**

> **Nota:** Os caminhos utilizados nos comandos `BULK INSERT` s√£o parametriz√°veis e devem ser ajustados conforme o ambiente local de execu√ß√£o.


A decis√£o de manter dados n√£o tipados nesta camada permite que a limpeza ocorra de forma controlada no SQL Server.

### ü•à Camada Silver (dim_)

* Persist√™ncia f√≠sica dos dados transformados e tipados

* Aplica√ß√£o de **PRIMARY KEY** e **FOREIGN KEY**

* Prepara√ß√£o de um **modelo dimensional (Star Schema)**

As tabelas desta camada s√£o a base confi√°vel para o consumo anal√≠tico.

### üîé Transforma√ß√µes via Views (vw_)

* As transforma√ß√µes entre Bronze e Silver s√£o feitas via **Views**

* Permite testar e ajustar regras de limpeza **sem reprocessar a carga f√≠sica**

* Facilita auditoria, manuten√ß√£o e rastreabilidade

## ‚úÖ Framework de Qualidade de Dados

Antes da carga definitiva na camada Silver, foi implementado um conjunto de queries de diagn√≥stico, atuando como um framework de Data Quality.

### Principais valida√ß√µes

* **Auditoria de Espa√ßos:** detec√ß√£o de espa√ßos extras com LEN(col) > LEN(TRIM(col))

* **Sanidade de IDs:** identifica√ß√£o de valores como 101.0 importados como string

* **Valida√ß√£o de Dom√≠nio:** meses fora do intervalo v√°lido (1‚Äì12)

* **Unicidade:** verifica√ß√£o de chaves prim√°rias duplicadas (GROUP BY + HAVING COUNT(*) > 1)

Essas valida√ß√µes permitem identificar problemas antes da persist√™ncia f√≠sica, evitando erros silenciosos no modelo anal√≠tico.

## ‚öôÔ∏è Decis√µes T√©cnicas de ETL
### Convers√£o de Tipagem Complexa

Para tratar IDs num√©ricos importados como strings decimais (ex: "101.0"), foi utilizada a convers√£o aninhada:

CAST(CAST(id_categoria AS FLOAT) AS INT)


Essa abordagem evita erros comuns do SQL Server ao tentar converter diretamente strings com ponto decimal para inteiros.

### Padroniza√ß√£o Sem√¢ntica de Strings

Foi desenvolvida uma l√≥gica de InitCap personalizada, com foco na est√©tica do dashboard sem comprometer o neg√≥cio:

* Primeira letra mai√∫scula, demais min√∫sculas

* Preserva√ß√£o de siglas em caixa alta (ex: **RH**, **TI**)

* Tratamento correto de delimitadores (ex: "Limpeza/Conserva√ß√£o")

### Integridade e Saneamento de Dados

* Registros com **IDs nulos na origem** foram identificados como causa raiz de duplicidades

* Esses registros foram descartados ainda na View (WHERE id IS NOT NULL)

* Valida√ß√£o cruzada garantiu que **toda categoria possua um Centro de Custo v√°lido** antes da carga na Silver

## üß© Modelo Dimensional (Silver)

O modelo foi constru√≠do seguindo o padr√£o Star Schema, com foco em performance e clareza anal√≠tica.

### Dimens√µes implementadas

* **dim_centro_custo** ‚Äî centros respons√°veis pelo or√ßamento

* **dim_categoria** ‚Äî natureza das despesas (com FK para centro de custo)

* **dim_camp_marketing** ‚Äî campanhas e refer√™ncia temporal

* **dim_fornecedores** ‚Äî fornecedores envolvidos nos lan√ßamentos

## üìÑ Tabela Fato ‚Äî fact_lancamentos (Silver Layer)

A tabela fact_lancamentos representa os lan√ßamentos financeiros efetivos e passou por um processo rigoroso de diagn√≥stico e saneamento antes da carga definitiva.

### Diagn√≥stico de Qualidade de Dados (Pr√©-Carga)

Durante o Data Profiling na tabela stg_lancamentos, foram identificados os seguintes pontos cr√≠ticos:

- **Integridade Temporal**
  - 27 registros com data nula (~0,6% do montante financeiro)

- **Integridade Referencial**
  - 65 registros (~1,3%) com Centros de Custo inexistentes na dimens√£o

- **Anomalias de Sinal**
  - Lan√ßamentos com valores negativos sem correla√ß√£o com estorno ou cancelamento

- **Inconsist√™ncia Sem√¢ntica**
  - Status de pagamento duplicados por varia√ß√£o de case e g√™nero
  - Exemplos: "Paga", "PAGO", "pago", "Pending"

---

### Decis√µes de Engenharia e Regras de Neg√≥cio

Para garantir confiabilidade anal√≠tica sem perda relevante de informa√ß√£o, foram aplicadas as seguintes estrat√©gias:

- **Descarte Estrat√©gico**
  - Registros sem data foram removidos devido ao alto risco anal√≠tico e baixo impacto financeiro (~0,6%)

- **Membro Coringa (Default Member)**
  - Cria√ß√£o do registro `-1 (N√ÉO IDENTIFICADO)` na `dim_centro_custo`
  - Permite preservar ~1,3% da massa financeira sem violar integridade referencial

- **Redund√¢ncia Defensiva de Valores**
  - `valor`: valor absoluto tratado com `ABS()`, protegido por `CHECK CONSTRAINT (> 0)`
  - `valor_original`: preserva√ß√£o do dado bruto para auditoria e rastreabilidade

- **Normaliza√ß√£o Sem√¢ntica**
  - Padroniza√ß√£o dos status de pagamento para apenas:
    - `Pago`
    - `Aberto`
  - Implementada via `CASE WHEN` com `UPPER()` e `TRIM()`

---

### Implementa√ß√£o T√©cnica

- Transforma√ß√µes centralizadas na `vw_lancamentos`
- Convers√£o de tipos:
  - `INT` para IDs
  - `DATETIME` para datas
  - `DECIMAL(16,2)` para valores
- Tratamento de IDs com res√≠duos decimais:
  - `CAST(CAST(col AS FLOAT) AS INT)`

### Status Final da fact_lancamentos

- **Primary Key:** definida sobre `id_lancamento`
- **Foreign Keys:** garantem v√≠nculo com dimens√µes v√°lidas ou membro coringa
- **Qualidade:** 100% dos registros respeitam regras de neg√≥cio e integridade referencial

## üì¶ Auditoria Final da Carga

Ap√≥s o carregamento da Silver:

* Carga realizada via INSERT INTO ... SELECT FROM vw_

* Valida√ß√£o de volumetria comparando tabelas atrav√©s de UNION ALL

* Diferen√ßas de registros foram analisadas e justificadas por filtros de qualidade

**Resultado:** dimens√µes prontas para consumo anal√≠tico, sem inconsist√™ncias estruturais.

## üìä Camada Gold e An√°lises

A camada Gold √© destinada ao consumo final no Power BI, utilizando:

* Tabelas fato de Lan√ßamentos e Or√ßamento

* Dimens√µes saneadas como filtros

* M√©tricas financeiras e or√ßament√°rias

*(Dashboards em evolu√ß√£o)*

## üõ†Ô∏è Stack Utilizada

* **SQL Server** ‚Äî ETL, modelagem dimensional e integridade

* **Python (Pandas)** ‚Äî ingest√£o e gera√ß√£o de dados sint√©ticos

* **Power BI** ‚Äî visualiza√ß√£o e an√°lise

* **Git / GitHub** ‚Äî versionamento e documenta√ß√£o

## üìå Objetivo do Projeto

Este projeto nasceu como uma forma pr√°tica de consolidar meus estudos em an√°lise de dados, BI e engenharia anal√≠tica, aplicando esses conceitos na constru√ß√£o de um pipeline completo de dados financeiros.

Mais do que o resultado final, o foco est√° no processo: tomar decis√µes t√©cnicas, lidar com dados imperfeitos e estruturar uma base anal√≠tica confi√°vel, pr√≥xima do que acontece no dia a dia de ambientes corporativos.

Ao longo do projeto, s√£o explorados principalmente:
- Pensamento arquitetural
- Cuidado e rigor com qualidade de dados
- Transforma√ß√£o de dados brutos em informa√ß√µes prontas para an√°lise 


## üìé Pr√≥ximos Passos

* Implementar o pipeline ETL da tabela fato fact_orcamentos

* Evoluir a camada Gold

* Publicar dashboards finais

* Adicionar diagrama visual da arquitetura

üì¨ Fique √† vontade para explorar o reposit√≥rio e entrar em contato para feedbacks ou sugest√µes.

